{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "pd.set_option(\"max_colwidth\", 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.1.2/libexec/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Run Spark on localhost\n",
    "spark = SparkSession\\\n",
    "    .Builder()\\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\")\\\n",
    "    .appName(\"wiki_bias\")\\\n",
    "    .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chriswallerstein/Development/python/wikipedia_bias/data/wiki_corpus_2022_2_16.csv\n",
      "/Users/chriswallerstein/Development/python/wikipedia_bias/data/wiki_corpus_2022_2_17.csv\n",
      "/Users/chriswallerstein/Development/python/wikipedia_bias/data/wiki_corpus_2022_2_13.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk(\"/Users/chriswallerstein/Development/python/wikipedia_bias/data\"):\n",
    "    for file in filenames:\n",
    "        print(os.path.join(dirname, file))\n",
    "\n",
    "wiki_data = spark.read\\\n",
    "    .option(\"mode\", \"dropmalformed\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"multiline\", \"true\")\\\n",
    "    .option(\"charset\", \"UTF-8\")\\\n",
    "    .csv(\"/Users/chriswallerstein/Development/python/wikipedia_bias/data/*.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# basic data cleansing\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "@F.udf\n",
    "def ascii_ignore(x):\n",
    "    return x.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    "wiki_data = wiki_data.dropna()\n",
    "wiki_data = wiki_data.withColumn(\"sentence_text\", ascii_ignore(\"sentence\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------------+--------------------+\n",
      "|                  id|       source|            sentence|       sentence_text|               words|\n",
      "+--------------------+-------------+--------------------+--------------------+--------------------+\n",
      "|20220216130833233044|conservapedia|right|thumb|the t...|right|thumb|the t...|[right, thumb, th...|\n",
      "|20220216130833233089|conservapedia|a great player bo...|a great player bo...|[a, great, player...|\n",
      "|20220216130833233103|conservapedia|in his career (18...|in his career (18...|[in, his, career,...|\n",
      "|20220216130833404323|conservapedia|thumb|left|buildi...|thumb|left|buildi...|[thumb, left, bui...|\n",
      "|20220216130833588118|conservapedia|robert lloyd dunc...|robert lloyd dunc...|[robert, lloyd, d...|\n",
      "+--------------------+-------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "from pyspark.ml.feature import RegexTokenizer, Tokenizer\n",
    "\n",
    "regex_tokenizer = RegexTokenizer(inputCol=\"sentence_text\", outputCol=\"words\", gaps=False, pattern=\"[a-z]+\")\n",
    "wiki_data = regex_tokenizer.transform(wiki_data)\n",
    "wiki_data.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               words|            features|\n",
      "+--------------------+--------------------+\n",
      "|[right, thumb, th...|(20579,[0,1,2,5,8...|\n",
      "|[a, great, player...|(20579,[1,2,5,8,1...|\n",
      "|[in, his, career,...|(20579,[0,1,2,3,4...|\n",
      "|[thumb, left, bui...|(20579,[0,2,4,5,6...|\n",
      "|[robert, lloyd, d...|(20579,[0,1,2,3,4...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vectorize words\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\")\n",
    "cv_model = cv.fit(wiki_data)\n",
    "wiki_data = cv_model.transform(wiki_data)\n",
    "wiki_data.select(\"words\", \"features\").show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|       source|label|\n",
      "+-------------+-----+\n",
      "|conservapedia|  2.0|\n",
      "|conservapedia|  2.0|\n",
      "|conservapedia|  2.0|\n",
      "|conservapedia|  2.0|\n",
      "|conservapedia|  2.0|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform label column (source)\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "si = StringIndexer(inputCol=\"source\", outputCol=\"label\")\n",
    "si_model = si.fit(wiki_data)\n",
    "wiki_data = si_model.transform(wiki_data)\n",
    "wiki_data.sample(True, 0.1).select(\"source\", \"label\").show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4749\n",
      "564\n"
     ]
    }
   ],
   "source": [
    "train, test = wiki_data.select(\"features\", \"label\").randomSplit([0.9,0.1])\n",
    "print(train.count())\n",
    "print(test.count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    features  \\\n0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)   \n1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)   \n2  (6.0, 3.0, 2.0, 6.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, ...)   \n3  (3.0, 1.0, 5.0, 3.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)   \n4  (3.0, 4.0, 3.0, 7.0, 3.0, 4.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)   \n\n   label                                                 rawPrediction  \\\n0    1.0   [5.112159899323037, 6.398755982340817, -11.510915881663854]   \n1    1.0   [5.112159899323037, 6.398755982340817, -11.510915881663854]   \n2    0.0      [380.3160592113952, -262.01303038796, -118.303028823435]   \n3    0.0   [275.5727825483716, -212.6299820055412, -62.94280054283031]   \n4    0.0  [196.22676782720345, -106.4359471708314, -89.79082065637205]   \n\n                                                       probability  prediction  \n0  [0.2164295135004896, 0.783570473437609, 1.3061901345478775e-08]         1.0  \n1  [0.2164295135004896, 0.783570473437609, 1.3061901345478775e-08]         1.0  \n2           [1.0, 1.0965307650501619e-279, 2.834532852316016e-217]         0.0  \n3            [1.0, 9.467456194216645e-213, 9.650509114290981e-148]         0.0  \n4            [1.0, 3.591310857363413e-132, 6.083305041761479e-125]         0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features</th>\n      <th>label</th>\n      <th>rawPrediction</th>\n      <th>probability</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n      <td>1.0</td>\n      <td>[5.112159899323037, 6.398755982340817, -11.510915881663854]</td>\n      <td>[0.2164295135004896, 0.783570473437609, 1.3061901345478775e-08]</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n      <td>1.0</td>\n      <td>[5.112159899323037, 6.398755982340817, -11.510915881663854]</td>\n      <td>[0.2164295135004896, 0.783570473437609, 1.3061901345478775e-08]</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(6.0, 3.0, 2.0, 6.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, ...)</td>\n      <td>0.0</td>\n      <td>[380.3160592113952, -262.01303038796, -118.303028823435]</td>\n      <td>[1.0, 1.0965307650501619e-279, 2.834532852316016e-217]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(3.0, 1.0, 5.0, 3.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n      <td>0.0</td>\n      <td>[275.5727825483716, -212.6299820055412, -62.94280054283031]</td>\n      <td>[1.0, 9.467456194216645e-213, 9.650509114290981e-148]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(3.0, 4.0, 3.0, 7.0, 3.0, 4.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n      <td>0.0</td>\n      <td>[196.22676782720345, -106.4359471708314, -89.79082065637205]</td>\n      <td>[1.0, 3.591310857363413e-132, 6.083305041761479e-125]</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try Logistic regression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(train)\n",
    "lr_predictions = lr_model.transform(test)\n",
    "lr_predictions.limit(5).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression f1 0.7625\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "print(f\"Linear regression f1 {evaluator.evaluate(lr_predictions):.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    features  \\\n0  (2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)   \n1  (4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     features-idf  \n0  (1.0389128282082822, 0.8339634986917686, 0.0, 0.0, 1.0444064164711266, 1.0133431134140298, 0.0, 0.0, 0.0, 1.7947749257157988, 1.8972454475295437, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2133493694678474, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5004578829707245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7144689507216615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.368613973478338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)  \n1                                                               (2.0778256564165645, 2.5018904960753057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7947749257157988, 0.0, 0.0, 0.0, 0.0, 0.0, 2.017069460423186, 0.0, 2.153231102414371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5476622049273234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features</th>\n      <th>features-idf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n      <td>(1.0389128282082822, 0.8339634986917686, 0.0, 0.0, 1.0444064164711266, 1.0133431134140298, 0.0, 0.0, 0.0, 1.7947749257157988, 1.8972454475295437, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2133493694678474, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5004578829707245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7144689507216615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.368613973478338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n      <td>(2.0778256564165645, 2.5018904960753057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7947749257157988, 0.0, 0.0, 0.0, 0.0, 0.0, 2.017069460423186, 0.0, 2.153231102414371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5476622049273234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create TF-IDF weightings - to be used later\n",
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "# we created the term frequency vectors above with CountVectorizer\n",
    "idf = IDF(inputCol=\"features\", outputCol=\"features-idf\")\n",
    "idfModel = idf.fit(wiki_data)\n",
    "wiki_data_idf = idfModel.transform(wiki_data)\n",
    "wiki_data_idf.sample(True, 0.0005)\\\n",
    "    .select(\"features\",\"features-idf\").toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "english_stop_words = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "sw_remover = StopWordsRemover(\n",
    "    inputCol=\"words\",\n",
    "    outputCol=\"sw_free_words\",\n",
    "    stopWords=english_stop_words)\n",
    "sw_free_wiki_data = sw_remover.transform(wiki_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n",
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n",
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n",
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n",
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n",
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(67, ('conservapedia', 'committee')),\n (58, ('conservapedia', 'american')),\n (27, ('conservapedia', 'also')),\n (23, ('conservapedia', 'peace')),\n (22, ('conservapedia', 'duncan')),\n (22, ('conservapedia', 'new')),\n (22, ('conservapedia', 'league')),\n (19, ('conservapedia', 'council')),\n (18, ('conservapedia', 'school')),\n (17, ('conservapedia', 'people'))]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten -> (source, word)\n",
    "sw_free_wiki_data_rdd = sw_free_wiki_data\\\n",
    "    .select(\"source\", \"sw_free_words\").rdd\\\n",
    "    .flatMapValues(lambda x: x)\n",
    "\n",
    "# convert each pair to (pair, 1) so that the occurrences can be counted\n",
    "# the key is now (source, word), i.e. (conservapedia, obamacare)\n",
    "sw_free_wiki_data_rdd = sw_free_wiki_data_rdd\\\n",
    "    .map(lambda x: (x, 1))\\\n",
    "    .reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# flip (key, count) to (count, key) and sort\n",
    "sw_free_wiki_data_rdd\\\n",
    "    .map(lambda x: (x[1], x[0]))\\\n",
    "    .sortByKey(ascending=False)\\\n",
    "    .filter(lambda x : x[1][0] == \"conservapedia\")\\\n",
    "    .take(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[(162, ('wikipedia', 'style')),\n (132, ('wikipedia', 'new')),\n (120, ('wikipedia', 'episode')),\n (106, ('wikipedia', 'width')),\n (103, ('wikipedia', 'align')),\n (93, ('wikipedia', 'faj')),\n (92, ('wikipedia', 'also')),\n (90, ('wikipedia', 'treaties')),\n (89, ('wikipedia', 'left')),\n (83, ('wikipedia', 'first'))]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw_free_wiki_data_rdd\\\n",
    "    .map(lambda x: (x[1], x[0]))\\\n",
    "    .sortByKey(ascending=False)\\\n",
    "    .filter(lambda x : x[1][0] == \"wikipedia\")\\\n",
    "    .take(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[(326, ('rational', 'right')),\n (253, ('rational', 'one')),\n (249, ('rational', 'also')),\n (234, ('rational', 'align')),\n (225, ('rational', 'people')),\n (211, ('rational', 'de')),\n (173, ('rational', 'px')),\n (172, ('rational', 'war')),\n (160, ('rational', 'even')),\n (159, ('rational', 'comfort'))]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw_free_wiki_data_rdd\\\n",
    "    .map(lambda x: (x[1], x[0]))\\\n",
    "    .sortByKey(ascending=False)\\\n",
    "    .filter(lambda x : x[1][0] == \"rational\")\\\n",
    "    .take(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n",
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n",
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n"
     ]
    }
   ],
   "source": [
    "# Use TD-IDF to find unique words in each source\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "wiki_data_by_source = sw_free_wiki_data_rdd.map(lambda x : x[0]).reduceByKey(lambda a,b: \" \".join([a,b]))\n",
    "column_names = [source[0] for source in wiki_data_by_source.toLocalIterator()]\n",
    "wiki_data_by_source = wiki_data_by_source.map(lambda x: x[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range = (1,1), max_df = .6, min_df = .05)\n",
    "corpus = []\n",
    "for it in wiki_data_by_source.toLocalIterator():\n",
    "    corpus.append(it[1:])\n",
    "X = vectorizer.fit_transform(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chriswallerstein/Development/python/wikipedia_bias/venv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "['aak', 'aaron', 'aba', 'abacetus', 'abahachi']"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "        aak     aaron       aba  abacetus  abahachi  abandoning  abandonment  \\\n0  0.000000  0.000000  0.000000  0.000000  0.000000    0.053074     0.000000   \n1  0.013833  0.000000  0.013833  0.013833  0.013833    0.000000     0.013833   \n2  0.000000  0.009822  0.000000  0.000000  0.000000    0.000000     0.000000   \n\n   abbotsford    abbott    abbrev  ...    zoning       zoo  zoological  \\\n0    0.000000  0.053074  0.000000  ...  0.000000  0.000000    0.000000   \n1    0.013833  0.000000  0.000000  ...  0.013833  0.000000    0.000000   \n2    0.000000  0.000000  0.009822  ...  0.000000  0.009822    0.009822   \n\n    zoology      zoos  zoroastrian  zoroastrianism  zoroastrians      zozo  \\\n0  0.000000  0.000000     0.000000        0.000000      0.000000  0.000000   \n1  0.000000  0.000000     0.000000        0.000000      0.000000  0.000000   \n2  0.009822  0.009822     0.009822        0.009822      0.009822  0.009822   \n\n     zwayne  \n0  0.000000  \n1  0.000000  \n2  0.009822  \n\n[3 rows x 15947 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aak</th>\n      <th>aaron</th>\n      <th>aba</th>\n      <th>abacetus</th>\n      <th>abahachi</th>\n      <th>abandoning</th>\n      <th>abandonment</th>\n      <th>abbotsford</th>\n      <th>abbott</th>\n      <th>abbrev</th>\n      <th>...</th>\n      <th>zoning</th>\n      <th>zoo</th>\n      <th>zoological</th>\n      <th>zoology</th>\n      <th>zoos</th>\n      <th>zoroastrian</th>\n      <th>zoroastrianism</th>\n      <th>zoroastrians</th>\n      <th>zozo</th>\n      <th>zwayne</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.053074</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.053074</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.013833</td>\n      <td>0.000000</td>\n      <td>0.013833</td>\n      <td>0.013833</td>\n      <td>0.013833</td>\n      <td>0.000000</td>\n      <td>0.013833</td>\n      <td>0.013833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.013833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.009822</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.009822</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.009822</td>\n      <td>0.009822</td>\n      <td>0.009822</td>\n      <td>0.009822</td>\n      <td>0.009822</td>\n      <td>0.009822</td>\n      <td>0.009822</td>\n      <td>0.009822</td>\n      <td>0.009822</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 15947 columns</p>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = X.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "data = df.transpose()\n",
    "data.columns = column_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conservapedia\n",
      "shortstop, stinging, seliger, localities, dickens, schappes, rarest, milam, trier, wagner, objection, wireless, attorneyscategory, attract\n",
      "---\n",
      "wikipedia\n",
      "aak, krlov, kucha, kuba, kuala, ktv, ktitel, ksqof, ksiyc, ksiniczka, krzysztof, krowa, kroll, krol\n",
      "---\n",
      "rational\n",
      "zwayne, souvent, joking, soviets, jolts, jon, sovereign, souzainterview, souza, jordan, souvenirs, joints, soutient, jornadas\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Find 20 unique words in each source\n",
    "top_dict = {}\n",
    "for c in range(3):\n",
    "    top = data.iloc[:,c].sort_values(ascending=False).head(20)\n",
    "    top_dict[data.columns[c]]= list(zip(top.index, top.values))\n",
    "\n",
    "for source, top_words in top_dict.items():\n",
    "    print(source)\n",
    "    print(', '.join([word for word, count in top_words[0:14]]))\n",
    "    print('---')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}