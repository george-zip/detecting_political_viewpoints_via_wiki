{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "pd.set_option(\"max_colwidth\", 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.1.2/libexec/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Run Spark on localhost\n",
    "spark = SparkSession\\\n",
    "    .Builder()\\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\")\\\n",
    "    .appName(\"wiki_bias\")\\\n",
    "    .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chriswallerstein/Development/python/wikipedia_bias/data/wiki_corpus_2022_2_16.csv\n",
      "/Users/chriswallerstein/Development/python/wikipedia_bias/data/wiki_corpus_2022_2_13.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk(\"/Users/chriswallerstein/Development/python/wikipedia_bias/data\"):\n",
    "    for file in filenames:\n",
    "        print(os.path.join(dirname, file))\n",
    "\n",
    "wiki_data = spark.read\\\n",
    "    .option(\"mode\", \"dropmalformed\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"multiline\", \"true\")\\\n",
    "    .option(\"charset\", \"UTF-8\")\\\n",
    "    .csv(\"/Users/chriswallerstein/Development/python/wikipedia_bias/data/*.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "# basic data cleansing\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "@F.udf\n",
    "def ascii_ignore(x):\n",
    "    return x.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    "wiki_data = wiki_data.dropna()\n",
    "wiki_data = wiki_data.withColumn(\"sentence_text\", ascii_ignore(\"sentence\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------------+--------------------+\n",
      "|                  id|       source|            sentence|       sentence_text|               words|\n",
      "+--------------------+-------------+--------------------+--------------------+--------------------+\n",
      "|20220216130833233044|conservapedia|right|thumb|the t...|right|thumb|the t...|[right, thumb, th...|\n",
      "|20220216130833233089|conservapedia|a great player bo...|a great player bo...|[a, great, player...|\n",
      "|20220216130833233103|conservapedia|in his career (18...|in his career (18...|[in, his, career,...|\n",
      "|20220216130833404323|conservapedia|thumb|left|buildi...|thumb|left|buildi...|[thumb, left, bui...|\n",
      "|20220216130833588118|conservapedia|robert lloyd dunc...|robert lloyd dunc...|[robert, lloyd, d...|\n",
      "+--------------------+-------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "from pyspark.ml.feature import RegexTokenizer, Tokenizer\n",
    "\n",
    "regex_tokenizer = RegexTokenizer(inputCol=\"sentence_text\", outputCol=\"words\", gaps=False, pattern=\"[a-z]+\")\n",
    "wiki_data = regex_tokenizer.transform(wiki_data)\n",
    "wiki_data.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               words|            features|\n",
      "+--------------------+--------------------+\n",
      "|[right, thumb, th...|(19156,[0,1,2,5,8...|\n",
      "|[a, great, player...|(19156,[1,2,5,8,1...|\n",
      "|[in, his, career,...|(19156,[0,1,2,3,4...|\n",
      "|[thumb, left, bui...|(19156,[0,2,4,5,6...|\n",
      "|[robert, lloyd, d...|(19156,[0,1,2,3,4...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vectorize words\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\")\n",
    "cv_model = cv.fit(wiki_data)\n",
    "wiki_data = cv_model.transform(wiki_data)\n",
    "wiki_data.select(\"words\", \"features\").show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|       source|label|\n",
      "+-------------+-----+\n",
      "|conservapedia|  2.0|\n",
      "|conservapedia|  2.0|\n",
      "|conservapedia|  2.0|\n",
      "|conservapedia|  2.0|\n",
      "|conservapedia|  2.0|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform label column (source)\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "si = StringIndexer(inputCol=\"source\", outputCol=\"label\")\n",
    "si_model = si.fit(wiki_data)\n",
    "wiki_data = si_model.transform(wiki_data)\n",
    "wiki_data.sample(True, 0.1).select(\"source\", \"label\").show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4421\n",
      "467\n"
     ]
    }
   ],
   "source": [
    "train, test = wiki_data.select(\"features\", \"label\").randomSplit([0.9,0.1])\n",
    "print(train.count())\n",
    "print(test.count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    features  \\\n0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)   \n1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)   \n2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)   \n3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)   \n4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)   \n\n   label                                                  rawPrediction  \\\n0    1.0  [10.199248346538464, 11.296519146393823, -21.495767492932288]   \n1    1.0  [10.199248346538464, 11.296519146393823, -21.495767492932288]   \n2    1.0  [10.199248346538464, 11.296519146393823, -21.495767492932288]   \n3    1.0  [10.199248346538464, 11.296519146393823, -21.495767492932288]   \n4    1.0  [10.199248346538464, 11.296519146393823, -21.495767492932288]   \n\n                                                      probability  prediction  \n0  [0.2502516134988297, 0.749748386501166, 4.299385657656396e-15]         1.0  \n1  [0.2502516134988297, 0.749748386501166, 4.299385657656396e-15]         1.0  \n2  [0.2502516134988297, 0.749748386501166, 4.299385657656396e-15]         1.0  \n3  [0.2502516134988297, 0.749748386501166, 4.299385657656396e-15]         1.0  \n4  [0.2502516134988297, 0.749748386501166, 4.299385657656396e-15]         1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features</th>\n      <th>label</th>\n      <th>rawPrediction</th>\n      <th>probability</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n      <td>1.0</td>\n      <td>[10.199248346538464, 11.296519146393823, -21.495767492932288]</td>\n      <td>[0.2502516134988297, 0.749748386501166, 4.299385657656396e-15]</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n      <td>1.0</td>\n      <td>[10.199248346538464, 11.296519146393823, -21.495767492932288]</td>\n      <td>[0.2502516134988297, 0.749748386501166, 4.299385657656396e-15]</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n      <td>1.0</td>\n      <td>[10.199248346538464, 11.296519146393823, -21.495767492932288]</td>\n      <td>[0.2502516134988297, 0.749748386501166, 4.299385657656396e-15]</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n      <td>1.0</td>\n      <td>[10.199248346538464, 11.296519146393823, -21.495767492932288]</td>\n      <td>[0.2502516134988297, 0.749748386501166, 4.299385657656396e-15]</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n      <td>1.0</td>\n      <td>[10.199248346538464, 11.296519146393823, -21.495767492932288]</td>\n      <td>[0.2502516134988297, 0.749748386501166, 4.299385657656396e-15]</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try Logistic regression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(train)\n",
    "lr_predictions = lr_model.transform(test)\n",
    "lr_predictions.limit(5).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression f1 0.8196\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "print(f\"Linear regression f1 {evaluator.evaluate(lr_predictions):.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(20411,[0,1,2,3,4...|\n",
      "|(20411,[0,1,8,120...|\n",
      "|(20411,[0,1,3,10,...|\n",
      "|(20411,[0,2,3,4,1...|\n",
      "|(20411,[0,2,3,4,7...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create TF-IDF weightings - to be used later\n",
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "# we created the term frequency vectors above with CountVectorizer\n",
    "idf = IDF(inputCol=\"features\", outputCol=\"features-idf\")\n",
    "idfModel = idf.fit(wiki_data)\n",
    "wiki_data_idf = idfModel.transform(wiki_data)\n",
    "wiki_data_idf.sample(True, 0.1)\\\n",
    "    .select(\"features\").show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "english_stop_words = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "sw_remover = StopWordsRemover(\n",
    "    inputCol=\"words\",\n",
    "    outputCol=\"sw_free_words\",\n",
    "    stopWords=english_stop_words)\n",
    "sw_free_wiki_data = sw_remover.transform(wiki_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n",
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n",
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n",
      "/usr/local/Cellar/apache-spark/3.1.2/libexec/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(22, ('conservapedia', 'duncan')),\n (15, ('conservapedia', 'also')),\n (13, ('conservapedia', 'chancellor')),\n (13, ('conservapedia', 'texas')),\n (12, ('conservapedia', 'party')),\n (11, ('conservapedia', 'state')),\n (11, ('conservapedia', 'states')),\n (9, ('conservapedia', 'former')),\n (9, ('conservapedia', 'system')),\n (8, ('conservapedia', 'category'))]"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten -> (source, word)\n",
    "sw_free_wiki_data_rdd = sw_free_wiki_data\\\n",
    "    .select(\"source\", \"sw_free_words\").rdd\\\n",
    "    .flatMapValues(lambda x: x)\n",
    "\n",
    "# convert each pair to (pair, 1) so that the occurrences can be counted\n",
    "# the key is now (source, word), i.e. (conservapedia, obamacare)\n",
    "sw_free_wiki_data_rdd = sw_free_wiki_data_rdd\\\n",
    "    .map(lambda x: (x, 1))\\\n",
    "    .reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# flip (key, count) to (count, key) and sort\n",
    "sw_free_wiki_data_rdd\\\n",
    "    .map(lambda x: (x[1], x[0]))\\\n",
    "    .sortByKey(ascending=False)\\\n",
    "    .filter(lambda x : x[1][0] == \"conservapedia\")\\\n",
    "    .take(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "[(162, ('wikipedia', 'style')),\n (119, ('wikipedia', 'episode')),\n (103, ('wikipedia', 'align')),\n (103, ('wikipedia', 'width')),\n (93, ('wikipedia', 'faj')),\n (90, ('wikipedia', 'treaties')),\n (83, ('wikipedia', 'new')),\n (83, ('wikipedia', 'also')),\n (80, ('wikipedia', 'text')),\n (80, ('wikipedia', 'left'))]"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw_free_wiki_data_rdd\\\n",
    "    .map(lambda x: (x[1], x[0]))\\\n",
    "    .sortByKey(ascending=False)\\\n",
    "    .filter(lambda x : x[1][0] == \"wikipedia\")\\\n",
    "    .take(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "[(311, ('rational', 'right')),\n (239, ('rational', 'one')),\n (233, ('rational', 'align')),\n (231, ('rational', 'also')),\n (211, ('rational', 'de')),\n (205, ('rational', 'people')),\n (171, ('rational', 'px')),\n (159, ('rational', 'comfort')),\n (154, ('rational', 'even')),\n (154, ('rational', 'war'))]"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw_free_wiki_data_rdd\\\n",
    "    .map(lambda x: (x[1], x[0]))\\\n",
    "    .sortByKey(ascending=False)\\\n",
    "    .filter(lambda x : x[1][0] == \"rational\")\\\n",
    "    .take(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}